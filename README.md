# ğŸ“Š CRM Analytics com Microsoft Fabric

Este projeto simula uma soluÃ§Ã£o moderna de CRM Analytics utilizando a plataforma Microsoft Fabric. A soluÃ§Ã£o envolve a geraÃ§Ã£o de dados sintÃ©ticos e tambÃ©m a integraÃ§Ã£o com dados reais via API pÃºblica, armazenados em Lakehouse com arquitetura Medallion, processamento e transformaÃ§Ã£o com PySpark, controle de versionamento via Delta Lake, automaÃ§Ã£o de pipelines e visualizaÃ§Ã£o interativa com Power BI.

---

## ğŸš€ Tecnologias Utilizadas

- [Microsoft Fabric](https://www.microsoft.com/en-us/microsoft-fabric)
- Lakehouse (Delta Lake)
- Power BI
- PySpark (via notebooks no Fabric)
- Pipelines do Fabric
- Python (com Faker e requests)
- SQL (DAX, Spark SQL)

---

## ğŸ›ï¸ Arquitetura Medallion

Este projeto segue o padrÃ£o Medallion para organizaÃ§Ã£o de dados:

### ğŸ¥‰ Bronze â€“ Raw Layer
> Armazenamento de dados brutos, simulados e reais, sem transformaÃ§Ãµes.

| Tabela               | Fonte                      | DescriÃ§Ã£o                             |
|----------------------|----------------------------|----------------------------------------|
| `bronze_clientes`    | Faker                      | Clientes fictÃ­cios                     |
| `bronze_produtos`    | Faker                      | Produtos com categorias e preÃ§os       |
| `bronze_vendas`      | Faker                      | HistÃ³rico de compras simuladas         |
| `bronze_estados_ibge`| API IBGE                   | Lista de estados brasileiros           |

---

### ğŸ¥ˆ Silver â€“ Clean Layer
> Dados tratados, com schemas padronizados, tipos ajustados e joins aplicados.

| Tabela               | DescriÃ§Ã£o                          |
|----------------------|------------------------------------|
| `dim_cliente`        | DimensÃ£o de clientes               |
| `dim_produto`        | DimensÃ£o de produtos               |
| `dim_tempo`          | DimensÃ£o temporal (2 anos)         |
| `dim_regional`       | DimensÃ£o geogrÃ¡fica padronizada    |
| `fato_vendas`        | Fato com chaves e mÃ©tricas         |

---

### ğŸ¥‡ Gold â€“ Business Layer
> Dados prontos para anÃ¡lise de negÃ³cio, agregaÃ§Ãµes e indicadores.

| Tabela                   | DescriÃ§Ã£o                           |
|--------------------------|-------------------------------------|
| `resumo_vendas_estado`   | Total de vendas por estado          |
| `clientes_ativos`        | Ranking de clientes por volume      |
| `top_produtos`           | Produtos mais vendidos              |

---

## ğŸ” SeguranÃ§a

- **Acesso controlado por workspace** no Microsoft Fabric
- **MÃ¡scara de dados sensÃ­veis**, como e-mails dos clientes
- **SeparaÃ§Ã£o de camadas**: acesso total sÃ³ em Bronze/Silver; leitura apenas na Gold
- Pronto para uso com **monitoramento e auditoria** via Fabric ou Azure Purview

---

## ğŸ•’ Controle de VersÃ£o de Dados (Delta Time Travel)

Este projeto utiliza Delta Lake como formato de armazenamento, permitindo versionamento automÃ¡tico de todas as tabelas. Isso possibilita:

- Recuperar o estado anterior de uma tabela
- Auditar transformaÃ§Ãµes e histÃ³rico de carga
- Refazer anÃ¡lises com base em versÃµes antigas

Exemplo de uso no notebook:

```sql
-- Consultar versÃ£o anterior da fato_vendas usando SQL
SELECT * FROM silver.fato_vendas VERSION AS OF 3
```
```PySpark:
-- Consultar versÃ£o anterior da fato_vendas usando PySpark
df_v2 = spark.read.format("delta") \
    .option("versionAsOf", 3) \
    .load("Tables/silver/fato_vendas")
```

## âš™ï¸ AutomaÃ§Ã£o com Pipelines

Todos os processos de ETL sÃ£o automatizados por Pipelines do Microsoft Fabric.

ğŸ” Pipelines Criados

| Pipeline                   | Etapas                           |
|--------------------------|-------------------------------------|
| `etl_bronze_to_silver`   | Limpeza, casting, joins, escrita na camada Silver          |
| `etl_silver_to_gold`     | AgregaÃ§Ãµes e geraÃ§Ã£o de indicadores finais      |
| `api_coleta_ibge`           | Coleta e atualizaÃ§Ã£o de dados reais da API IBGE              |

Cada pipeline pode ser agendado para execuÃ§Ã£o automÃ¡tica (ex: diariamente) ou manual.

---

## ğŸ“Š Dashboards no Power BI

- ğŸ—ºï¸ Mapa de vendas por estado (mapa e grÃ¡fico de barras)
- ğŸ“¦ Produtos mais vendidos
- ğŸ‘¥ Clientes mais ativos
- ğŸ“‰ EvoluÃ§Ã£o de vendas (linha temporal)

> Os dashboards foram construÃ­dos diretamente no Power BI dentro do Fabric, com conexÃ£o nativa ao Lakehouse.

ğŸ“· Imagens estÃ£o disponÃ­veis na pasta /imagens/dashboard.png.

---

## âš¡ Boas PrÃ¡ticas de Performance

- Armazenamento em Delta Lake (compactaÃ§Ã£o + versionamento)
- Partitioning nas tabelas Silver e Gold (estado, data)
- Reuso de notebooks como mÃ³dulos reutilizÃ¡veis
- SeparaÃ§Ã£o clara de responsabilidades entre camadas
- ETL incremental com controle de timestamp futuro (opcional)

---

## ğŸ“ Estrutura do Projeto

```plaintext
crm-analytics-fabric/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ geracao_dados.ipynb
â”‚   â”œâ”€â”€ coleta_api_ibge.ipynb
â”‚   â”œâ”€â”€ bronze_to_silver.ipynb
â”‚   â””â”€â”€ silver_to_gold.ipynb
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ etl_bronze_to_silver.json
â”‚   â”œâ”€â”€ etl_silver_to_gold.json
â”‚   â””â”€â”€ api_coleta_ibge.json
â”œâ”€â”€ modelagem/
â”‚   â””â”€â”€ modelo_dimensional.drawio
â”œâ”€â”€ imagens/
â”‚   â””â”€â”€ dashboard.png
â”œâ”€â”€ README.md
```
---

## ğŸ§  CompetÃªncias Demonstrados

âœ”ï¸ Modelagem dimensional (estrela)
âœ”ï¸ Lakehouse Architecture
âœ”ï¸ Arquitetura Medallion (Bronze â†’ Silver â†’ Gold)
âœ”ï¸ ETL em PySpark
âœ”ï¸ Delta Time Travel (versionamento de dados)
âœ”ï¸ AutomaÃ§Ã£o com Pipelines do Fabric
âœ”ï¸ VisualizaÃ§Ã£o com Power BI
âœ”ï¸ SeguranÃ§a e boas prÃ¡ticas de performance

---

**Autor:** Danillo Oliveira  
**LinkedIn:** https://www.linkedin.com/in/danillobsoliveira/ 

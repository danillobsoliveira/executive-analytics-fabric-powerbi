# ğŸ“Š CRM Analytics with Microsoft Fabric

This project simulates a modern CRM Analytics solution using the Microsoft Fabric platform. It involves generating synthetic data as well as integrating real-world data from a public API, storing it in a Lakehouse using the Medallion architecture, processing and transforming it with PySpark, leveraging Delta Lake versioning, automating pipelines, and building interactive dashboards with Power BI.

---

## ğŸš€ Technologies Used

- [Microsoft Fabric](https://www.microsoft.com/en-us/microsoft-fabric)
- Lakehouse (Delta Lake)
- Power BI
- PySpark (via Fabric notebooks)
- Fabric Pipelines
- Python (with Faker and requests)
- SQL (DAX, Spark SQL)

---

# âš™ï¸ Project Structure and Environment Strategy

To ensure scalability, maintainability, and adherence to security and CI/CD best practices, this project is organized into two primary environments, each aligned with a specific team responsibility:

- `CRM Engineering`: Responsible for ingestion and transformation (Bronze & Silver layers)
- `CRM Analytics`: Focused on curated data, semantic modeling, and business reporting (Gold layer)

Each environment is structured into **three isolated workspaces** â€” Development (`Dev`), Staging (`Staging`), and Production (`Prod`) â€” to enable safe delivery workflows and strict access control.

---

## ğŸ› ï¸ Environment Breakdown

| Workspace Name                                                                 | Purpose                                                                 |
|--------------------------------------------------------------------------------|-------------------------------------------------------------------------|
| [`CRM_Engineering_Dev`](./images/infra/workspace-crm-engineering-dev.png)     | Development of pipelines, notebooks, and ETL logic for Bronze/Silver.   |
| [`CRM_Engineering_Staging`](./images/infra/workspace-crm-engineering-staging.png) | Testing and validation of stable pipelines before production release.   |
| [`CRM_Engineering_Prod`](./images/infra/workspace-crm-engineering-prod.png)   | Production-grade ingestion and transformation with monitoring enabled.  |
| [`CRM_Analytics_Dev`](./images/infra/workspace-crm-analytics-dev.png)         | Development of semantic models and Power BI dashboards (Gold layer).    |
| [`CRM_Analytics_Staging`](./images/infra/workspace-crm-analytics-staging.png) | QA and stakeholder review of reports and models before publication.     |
| [`CRM_Analytics_Prod`](./images/infra/workspace-crm-analytics-prod.png)       | Live environment for business reporting and analytics delivery.         |

---

## ğŸ” Why This Structure?

This multi-workspace strategy aligns with enterprise best practices in **data platform governance**:

- âœ… **Security by Design**: Access is isolated by role and stage. Engineers have full access to Bronze/Silver; analysts only to Gold (read-only in production).
- âœ… **Separation of Concerns**: Engineering and analytics teams operate in isolated environments to avoid conflict and ensure autonomy.
- âœ… **CI/CD Readiness**: Each workspace is linked to a dedicated Git branch, enabling automated deployment pipelines per stage (e.g., `Dev`, `Staging`, `Prod`).
- âœ… **Safe Experimentation**: Development environments allow rapid prototyping without affecting production data or dashboards.
- âœ… **Audit & Compliance**: Production workspaces are monitored, versioned, and subject to strict controls for traceability.

---

ğŸ“ Workspace and access configuration images are stored in:
- [`/images/infra`](./images/infra) â€“ Workspace setup and Git integration
- [`/images/security`](./images/security) â€“ Role-based access control and group definitions

---

## ğŸ” Security and Access Management

This project follows best practices for data access governance using **RBAC (Role-Based Access Control)** and the **Principle of Least Privilege (PoLP)** to ensure secure and organized collaboration between different data roles in Microsoft Fabric.

1. **Create Azure Entra users**  
   Two internal users were created to simulate real enterprise roles:
   - [`dataEngineer@yourdomain.com`](images/security/user-data-engineer.png)
   - [`dataAnalyst@yourdomain.com`](images/security/user-data-analyst.png)

2. **Create Azure Entra security groups**
   - [`Data Engineers`](images/security/group-data-engineers.png): Group of Data Engineers responsible for designing, building, and maintaining scalable data pipelines, lakehouses, and transformations.
   - [`Data Analysts`](images/security/group-data-analysts.png): Group of Data Analysts focused on exploring, interpreting, and visualizing business data to generate insights.

3. **Create dedicated workspaces in Fabric**
   - [`CRM_Engineering_Dev`](images/infra/workspace-crm-engineering-dev.png): Workspace for data engineering tasks â€“ ingestion and transformation of data (Bronze & Silver layers).
   - [`CRM_Analytics_Dev`](images/infra/workspace-crm-analytics-dev.png): Workspace for curated data and reporting â€“ Gold layer, semantic models, and Power BI dashboards.

4. **Assign roles to groups within workspaces**
   - In [`CRM_Engineering_Dev`](images/security/access-crm-engineering-dev.png), the **Data Engineers** group was added as `Contributors`.
   - In [`CRM_Analytics_Dev`](images/security/access-crm-analytics-dev.png), the **Data Analysts** group was added as `Contributors`.

---

## ğŸ›ï¸ Medallion Architecture

This project follows the Medallion data architecture pattern:

### ğŸ¥‰ Bronze â€“ Raw Layer
> Storage of raw data (synthetic and real), without transformations.

| Table               | Source                      | Description                             |
|----------------------|----------------------------|----------------------------------------|
| `bronze_customer`    | Faker                      | Synthetic customer records                     |
| `bronze_products`    | Faker                      | Products with categories and pricing       |
| `bronze_sales`      | Faker                      | Simulated sales history         |
| `bronze_ibge_states`| API IBGE                   | Official list of Brazilian states           |

---

### ğŸ¥ˆ Silver â€“ Clean Layer
> Cleaned data with standardized schemas, adjusted data types, and applied joins.

| Table               | Description                          |
|----------------------|------------------------------------|
| `dim_customer`        | Customer dimension               |
| `dim_product`        | Product dimension               |
| `dim_time`          | Time dimension (2 years range)         |
| `dim_geographic`       | Standardized geographic dimension    |
| `fact_sales`        | 	Fact table with keys and metrics         |

---

### ğŸ¥‡ Gold â€“ Business Layer
> Final business-ready data for aggregations and key indicators.

| Table                   | Description                           |
|--------------------------|-------------------------------------|
| `total_sales_state`   | Total sales by state          |
| `top_customers`        | Top customers by volume      |
| `top_products`           | Best-selling products              |

---

## ğŸ” Security

- **Workspace-level access control** in Microsoft Fabric
- **Data masking for sensitive fields**, such as customer emails
- **Layer-based access separation**: full access to Bronze/Silver, read-only access to Gold
- Ready for **auditing and monitoring** via Fabric or Azure Purview

---

## ğŸ•’ Data Versioning with Delta Time Travel

This project uses Delta Lake as the storage format, allowing automatic versioning of all tables. This enables:

- Restore previous versions of any table
- Audit transformations and load history
- Re-run analyses based on historical versions

Example usage in a notebook:

```sql
-- Query a previous version of the sales fact table (SQL)
SELECT * FROM silver.fato_vendas VERSION AS OF 3
```
```python
# Query a previous version using PySpark
df_v2 = spark.read.format("delta") \
    .option("versionAsOf", 3) \
    .load("Tables/silver/fact_sales")
```

## âš™ï¸ Pipeline Automation

All ETL processes are automated using Microsoft Fabric Pipelines.

ğŸ” Created Pipelines

| Pipeline                   | Steps Description                           |
|--------------------------|-------------------------------------|
| `etl_bronze_to_silver`   | Cleaning, casting, joins, write to Silver          |
| `etl_silver_to_gold`     | Aggregations and final indicators generation      |
| `api_collection_ibge`           | Real-time data collection from IBGE API              |

Each pipeline can be scheduled (e.g., daily) or triggered manually.

---

## ğŸ“Š Power BI Dashboards

- ğŸ—ºï¸ Sales map by state (map and bar chart)
- ğŸ“¦ Top-selling products
- ğŸ‘¥ Most active customers
- ğŸ“‰ Sales trend over time (line chart)

> Dashboards were built directly within Power BI in Fabric, using native Lakehouse connections.

ğŸ“· Dashboard screenshots are available in /imagens/dashboard.png.

---

## âš¡ Performance Best Practices

- Storage in Delta Lake (compression + versioning)
- Table partitioning in Silver and Gold layers (e.g., by state or date)
- Reusable notebook modules
- Clear separation of responsibilities across layers
- Incremental ETL with future timestamp control (optional)

---

## ğŸ“ Project Structure

```plaintext
crm-analytics-fabric/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ geracao_dados.ipynb
â”‚   â”œâ”€â”€ coleta_api_ibge.ipynb
â”‚   â”œâ”€â”€ bronze_to_silver.ipynb
â”‚   â””â”€â”€ silver_to_gold.ipynb
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ etl_bronze_to_silver.json
â”‚   â”œâ”€â”€ etl_silver_to_gold.json
â”‚   â””â”€â”€ api_coleta_ibge.json
â”œâ”€â”€ modelagem/
â”‚   â””â”€â”€ modelo_dimensional.drawio
â”œâ”€â”€ imagens/
â”‚   â””â”€â”€ dashboard.png
â”œâ”€â”€ README.md
```
---

## ğŸ§  Demonstrated Skills

- âœ”ï¸ Dimensional modeling (star schema)
- âœ”ï¸ Lakehouse architecture
- âœ”ï¸ Medallion architecture (Bronze â†’ Silver â†’ Gold)
- âœ”ï¸ ETL with PySpark
- âœ”ï¸ Delta Time Travel (data versioning)
- âœ”ï¸ Automation with Fabric Pipelines
- âœ”ï¸ Data visualization with Power BI
- âœ”ï¸ Security and performance best practices

---

**Author:** Danillo Oliveira  
**LinkedIn:** https://www.linkedin.com/in/danillobsoliveira/ 
